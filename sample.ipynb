import numpy as np
import torch
import json

def squad_processing(f):
    with open(f) as file:
        data = json.load(file)
    for par in data['data']:
        title = " ".join((par['title'].split("_")))
        for elem in par['paragraphs']:
            context = elem['context']
            if title.lower() not in context[:100].lower():
                context = title + " " + context
                elem['context'] = context
                for chunk in elem['qas']:
                    for ans in chunk['answers']:
                        ans['answer_start'] += len(title)+1
                print(elem)
                        

def NQ_processing(f):
    file_data = []
    with open(f, 'r') as file:
        json_l = list(file)
        for json_str in json_l:
            result = json.loads(json_str)
            file_data.append(result)
        
    examples = []
    
    # collecting the examples themselves
    x = file_data
    for k in range(len(x)):
        #print(x[k].keys())
        doc_tokens = []
        for i in range(len(x[k]['document_tokens'])):
            if x[k]['document_tokens'][i]['html_token'] == False:
                doc_tokens.append(x[k]['document_tokens'][i]['token'])
                
        question = x[k]['question_tokens']

        answers_text = []
        answers_ranges = []
        for j in range(len(x[k]['long_answer_candidates'])):
            start_token = x[k]['long_answer_candidates'][j]['start_token']
            end_token = x[k]['long_answer_candidates'][j]['end_token']
            answers_ranges.append([start_token, end_token])
            answers_text.append(doc_tokens[start_token: end_token])

        examples.append({'doc':doc_tokens, 'answer_text': answers_text, 'answer_ranges':answers_ranges, 'question':question})
        
    # writing to a pandas dataframe 
    with open('NQ_clean_sample.json', 'w') as f:
        json.dump(examples, f)

    return examples
